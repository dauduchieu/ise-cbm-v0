{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2a156c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Param\n",
    "# test = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90e029",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_test = True\n",
    "if test == \"False\" or test == False:\n",
    "    is_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2e60a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3db3c56d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader\n",
    "from utils.data_io import join_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08cc2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2520ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_loader.get_data_train()\n",
    "test_df = data_loader.get_data_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ffb166",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_desc = data_loader.get_data_desc()\n",
    "\n",
    "label_column = data_desc['label_column']\n",
    "text_column = data_desc['text_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f76d9830",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['coronary', 'myocardial', 'hypertension', 'cardiac', 'systolic', 'colitis', 'esophageal', 'gastrointestinal', 'bowel', 'duodenal', 'defect', 'loss', 'airway', 'graft', 'respiratory', 'cancer', 'carcinoma', 'sarcoma', 'malignancy', 'chemotherapy', 'brain', 'cerebral', 'neuronal', 'motor', 'cord']\n"
     ]
    }
   ],
   "source": [
    "keyword_concepts = data_loader.get_keyword_concepts()\n",
    "keywords = []\n",
    "for k in keyword_concepts.keys():\n",
    "    keywords += keyword_concepts[k]\n",
    "\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21a05ade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cardiac Function and Disorders',\n",
       " 'Heart Muscle and Blood Pressure',\n",
       " 'Coronary Artery Issues',\n",
       " 'Intestinal and Esophageal Conditions',\n",
       " 'Gastrointestinal Tract Ailments',\n",
       " 'Inflammatory Bowel Diseases',\n",
       " 'General Pathological States',\n",
       " 'Respiratory System Impairments',\n",
       " 'Tissue and Graft Issues',\n",
       " 'Malignant Tumors and Growths',\n",
       " 'Cancer Treatment and Types',\n",
       " 'Oncological Malignancies',\n",
       " 'Central and Peripheral Nervous System Disorders',\n",
       " 'Brain and Cerebral Conditions',\n",
       " 'Spinal Cord and Motor Function Impairment']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abstract_concepts = data_loader.get_abstract_concepts()\n",
    "abstract_concepts = [ac['abstract_concept_name'] for ac in abstract_concepts]\n",
    "abstract_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccc8e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea1797b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "le.fit(train_df[label_column])\n",
    "train_df[label_column] = le.transform(train_df[label_column])\n",
    "test_df[label_column] = le.transform(test_df[label_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e7db2b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cardiovascular diseases',\n",
       " 'digestive system diseases',\n",
       " 'general pathological conditions',\n",
       " 'neoplasms',\n",
       " 'nervous system diseases']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = list(le.classes_)\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ce8535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_test:\n",
    "    train_df = train_df.groupby(label_column).sample(1)\n",
    "    test_df = test_df.groupby(label_column).sample(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "598efcac",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = train_df[text_column].to_list()\n",
    "train_labels = train_df[label_column].to_list()\n",
    "test_texts = test_df[text_column].to_list()\n",
    "test_labels = test_df[label_column].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ef67e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01a52883",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fe9d7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import networkx as nx\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b661721",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptNetwork(nn.Module):\n",
    "    def __init__(self, concept_names, embedding_dim, keyword_nli_model_path, abstract_nli_model_path):\n",
    "        super(ConceptNetwork, self).__init__()\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.concept_names = concept_names  # [keywords, abstract_concepts, labels]\n",
    "        \n",
    "        # Initialize concept embeddings for each layer\n",
    "        self.keyword_embeddings = nn.Parameter(torch.randn(len(concept_names[0]), embedding_dim))\n",
    "        self.abstract_embeddings = nn.Parameter(torch.randn(len(concept_names[1]), embedding_dim))\n",
    "        self.label_embeddings = nn.Parameter(torch.randn(len(concept_names[2]), embedding_dim))\n",
    "        \n",
    "        # Beta parameters for reliability\n",
    "        self.keyword_betas = nn.Parameter(torch.ones(len(concept_names[0])))\n",
    "        self.abstract_betas = nn.Parameter(torch.ones(len(concept_names[1])))\n",
    "        \n",
    "        # Shared semantic predictor\n",
    "        self.semantic_predictor = nn.Linear(embedding_dim, 384)  # Adjusted for all-MiniLM-L6-v2 output\n",
    "        \n",
    "        # Load NLI scorers\n",
    "        self.keyword_scorer, self.keyword_tokenizer = load_model(keyword_nli_model_path)\n",
    "        self.abstract_scorer, self.abstract_tokenizer = load_model(abstract_nli_model_path)\n",
    "        \n",
    "        # Final predictor: expects input from abstract layer scores directly\n",
    "        self.final_predictor = nn.Linear(len(concept_names[1]), len(concept_names[2]))\n",
    "        \n",
    "    def forward(self, texts, device):\n",
    "        batch_size = len(texts)\n",
    "        \n",
    "        # Get concept scores for keyword layer\n",
    "        keyword_scores = []\n",
    "        for concept_name in self.concept_names[0]:\n",
    "            inputs = self.keyword_tokenizer(texts, [concept_name] * batch_size, \n",
    "                                         return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.keyword_scorer(**inputs)\n",
    "                scores = torch.softmax(outputs.logits, dim=-1)[:, 1]  # Probability of label 1\n",
    "            keyword_scores.append(scores)\n",
    "        keyword_scores = torch.stack(keyword_scores, dim=1)  # [batch_size, n_keywords]\n",
    "        \n",
    "        # Keyword layer output (not used in final prediction, kept for semantic loss)\n",
    "        keyword_output = keyword_scores @ (self.keyword_embeddings * self.keyword_betas.unsqueeze(-1))\n",
    "        \n",
    "        # Abstract layer\n",
    "        abstract_scores = []\n",
    "        for concept_name in self.concept_names[1]:\n",
    "            inputs = self.abstract_tokenizer(texts, [concept_name] * batch_size,\n",
    "                                          return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "            with torch.no_grad():\n",
    "                outputs = self.abstract_scorer(**inputs)\n",
    "                scores = torch.softmax(outputs.logits, dim=-1)[:, 1]\n",
    "            abstract_scores.append(scores)\n",
    "        abstract_scores = torch.stack(abstract_scores, dim=1)  # [batch_size, n_abstract_concepts]\n",
    "        \n",
    "        # Label layer: use abstract_scores directly for prediction\n",
    "        predictions = self.final_predictor(abstract_scores)\n",
    "        \n",
    "        # Semantic embeddings for loss computation\n",
    "        keyword_semantic = self.semantic_predictor(self.keyword_embeddings)\n",
    "        abstract_semantic = self.semantic_predictor(self.abstract_embeddings)\n",
    "        label_semantic = self.semantic_predictor(self.label_embeddings)\n",
    "        \n",
    "        return predictions, keyword_semantic, abstract_semantic, label_semantic, keyword_scores, abstract_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa627de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_texts, train_labels, val_texts, val_labels, concept_names, sbert_embeddings,\n",
    "                batch_size=16, num_epochs=100, patience=5, lambda_semantic=1.0, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    mse_loss = nn.MSELoss()\n",
    "    \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float('inf')\n",
    "    patience_counter = 0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        epoch_train_loss = 0\n",
    "        for i in tqdm(range(0, len(train_texts), batch_size), desc=f\"Epoch {epoch+1}\"):\n",
    "            batch_texts = train_texts[i:i+batch_size]\n",
    "            batch_labels = torch.tensor(train_labels[i:i+batch_size], dtype=torch.long).to(device)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            predictions, keyword_semantic, abstract_semantic, label_semantic, _, _ = model(batch_texts, device)\n",
    "            \n",
    "            # Predictor loss\n",
    "            pred_loss = criterion(predictions, batch_labels)\n",
    "            \n",
    "            # Semantic loss\n",
    "            semantic_loss = 0\n",
    "            for layer_idx, (embeddings, concepts) in enumerate(zip(\n",
    "                [keyword_semantic, abstract_semantic, label_semantic],\n",
    "                concept_names)):\n",
    "                sbert_emb = torch.tensor(sbert_embeddings[layer_idx], device=device, dtype=torch.float32)\n",
    "                semantic_loss += mse_loss(embeddings, sbert_emb)\n",
    "            \n",
    "            total_loss = pred_loss + lambda_semantic * semantic_loss\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_train_loss += total_loss.item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(0, len(val_texts), batch_size):\n",
    "                batch_texts = val_texts[i:i+batch_size]\n",
    "                batch_labels = torch.tensor(val_labels[i:i+batch_size], dtype=torch.long).to(device)\n",
    "                \n",
    "                predictions, keyword_semantic, abstract_semantic, label_semantic, _, _ = model(batch_texts, device)\n",
    "                pred_loss = criterion(predictions, batch_labels)\n",
    "                semantic_loss = 0\n",
    "                for layer_idx, (embeddings, concepts) in enumerate(zip(\n",
    "                    [keyword_semantic, abstract_semantic, label_semantic],\n",
    "                    concept_names)):\n",
    "                    sbert_emb = torch.tensor(sbert_embeddings[layer_idx], device=device, dtype=torch.float32)\n",
    "                    semantic_loss += mse_loss(embeddings, sbert_emb)\n",
    "                val_loss += (pred_loss + lambda_semantic * semantic_loss).item()\n",
    "        \n",
    "        avg_train_loss = epoch_train_loss / (len(train_texts) // batch_size + 1)\n",
    "        avg_val_loss = val_loss / (len(val_texts) // batch_size + 1)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        val_losses.append(avg_val_loss)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss\n",
    "            patience_counter = 0\n",
    "            torch.save(model.state_dict(), 'best_model.pt')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            if patience_counter >= patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                break\n",
    "    \n",
    "    # Plot losses\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(train_losses, label='Train Loss')\n",
    "    plt.plot(val_losses, label='Val Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    plt.savefig('loss_plot.png')\n",
    "    plt.close()\n",
    "    \n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1c93e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_texts, test_labels, concept_names, batch_size=16, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in tqdm(range(0, len(test_texts), batch_size), desc=\"Testing\"):\n",
    "            batch_texts = test_texts[i:i+batch_size]\n",
    "            batch_labels = test_labels[i:i+batch_size]\n",
    "            \n",
    "            outputs, _, _, _, _, _ = model(batch_texts, device)\n",
    "            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n",
    "            predictions.extend(preds)\n",
    "            true_labels.extend(batch_labels)\n",
    "    \n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true_labels, predictions, target_names=concept_names[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4ff87012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def interpretable_prediction(model, test_text, test_label, concept_names, device='cuda'):\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"\\nInterpretable Prediction for Sample:\")\n",
    "    print(f\"Input Text: {test_text}\")\n",
    "    print(f\"True Label: {concept_names[2][test_label]}\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Process single sample\n",
    "        predictions, _, _, _, keyword_scores, abstract_scores = model([test_text], device)\n",
    "        \n",
    "        # Keyword layer activations\n",
    "        print(\"\\nKeyword Layer Activations:\")\n",
    "        for concept_name, score in zip(concept_names[0], keyword_scores[0]):\n",
    "            print(f\"  {concept_name}: {score:.4f}\")\n",
    "        \n",
    "        # Abstract layer activations\n",
    "        print(\"\\nAbstract Layer Activations:\")\n",
    "        for concept_name, score in zip(concept_names[1], abstract_scores[0]):\n",
    "            print(f\"  {concept_name}: {score:.4f}\")\n",
    "        \n",
    "        # Label layer predictions\n",
    "        label_probs = torch.softmax(predictions, dim=-1)[0]\n",
    "        print(\"\\nLabel Layer Probabilities:\")\n",
    "        for concept_name, prob in zip(concept_names[2], label_probs):\n",
    "            print(f\"  {concept_name}: {prob:.4f}\")\n",
    "        \n",
    "        # Final prediction\n",
    "        predicted_label_idx = torch.argmax(predictions, dim=-1).item()\n",
    "        print(f\"\\nPredicted Label: {concept_names[2][predicted_label_idx]}\")\n",
    "        \n",
    "        return keyword_scores[0].cpu().numpy(), abstract_scores[0].cpu().numpy(), label_probs.cpu().numpy(), predicted_label_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5de08c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_network(model, concept_names, keyword_scores, abstract_scores, label_probs, predicted_label_idx, output_file='network_visualization.png'):\n",
    "    G = nx.DiGraph()\n",
    "    \n",
    "    # Add nodes for each layer\n",
    "    for i, keyword in enumerate(concept_names[0]):\n",
    "        G.add_node(f\"K_{i}\", label=keyword, layer='keyword', score=keyword_scores[i])\n",
    "    \n",
    "    for i, abstract in enumerate(concept_names[1]):\n",
    "        G.add_node(f\"A_{i}\", label=abstract, layer='abstract', score=abstract_scores[i])\n",
    "    \n",
    "    for i, label in enumerate(concept_names[2]):\n",
    "        G.add_node(f\"L_{i}\", label=label, layer='label', score=label_probs[i])\n",
    "    \n",
    "    # Add edges: keyword -> abstract, abstract -> label\n",
    "    for i in range(len(concept_names[0])):\n",
    "        for j in range(len(concept_names[1])):\n",
    "            # Use beta weights for keyword -> abstract edges\n",
    "            weight = model.keyword_betas[i].item() * model.abstract_betas[j].item()\n",
    "            G.add_edge(f\"K_{i}\", f\"A_{j}\", weight=weight)\n",
    "    \n",
    "    for i in range(len(concept_names[1])):\n",
    "        for j in range(len(concept_names[2])):\n",
    "            # Use final predictor weights for abstract -> label edges\n",
    "            weight = model.final_predictor.weight[j, i].item()\n",
    "            G.add_edge(f\"A_{i}\", f\"L_{j}\", weight=weight)\n",
    "    \n",
    "    # Define node positions for layered layout\n",
    "    pos = {}\n",
    "    max_nodes = max(len(concept_names[0]), len(concept_names[1]), len(concept_names[2]))\n",
    "    for i, keyword in enumerate(concept_names[0]):\n",
    "        pos[f\"K_{i}\"] = (0, max_nodes - i * max_nodes / len(concept_names[0]))\n",
    "    for i, abstract in enumerate(concept_names[1]):\n",
    "        pos[f\"A_{i}\"] = (1, max_nodes - i * max_nodes / len(concept_names[1]))\n",
    "    for i, label in enumerate(concept_names[2]):\n",
    "        pos[f\"L_{i}\"] = (2, max_nodes - i * max_nodes / len(concept_names[2]))\n",
    "    \n",
    "    # Node colors and sizes based on scores\n",
    "    node_colors = []\n",
    "    node_sizes = []\n",
    "    for node in G.nodes(data=True):\n",
    "        score = node[1]['score']\n",
    "        node_colors.append(score)\n",
    "        node_sizes.append(500 + score * 2000)  # Scale size based on score\n",
    "    \n",
    "    # Edge widths based on weights\n",
    "    edge_widths = [abs(G[u][v]['weight']) * 2 for u, v in G.edges()]\n",
    "    \n",
    "    # Plot the graph\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    nx.draw_networkx_nodes(G, pos, node_color=node_colors, node_size=node_sizes, cmap=cm.viridis)\n",
    "    nx.draw_networkx_edges(G, pos, width=edge_widths, alpha=0.5)\n",
    "    \n",
    "    # Add labels (concept names and scores)\n",
    "    labels = {node: f\"{data['label']}\\n{data['score']:.2f}\" for node, data in G.nodes(data=True)}\n",
    "    nx.draw_networkx_labels(G, pos, labels, font_size=8)\n",
    "    \n",
    "    # Highlight predicted label\n",
    "    predicted_node = f\"L_{predicted_label_idx}\"\n",
    "    nx.draw_networkx_nodes(G, pos, nodelist=[predicted_node], node_color='red', node_size=node_sizes[list(G.nodes).index(predicted_node)])\n",
    "    \n",
    "    plt.title(\"Concept Network Visualization\")\n",
    "    plt.show()\n",
    "    plt.savefig(output_file)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3fc4b4d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(path):\n",
    "    model = BertForSequenceClassification.from_pretrained(path)\n",
    "    tokenizer = BertTokenizer.from_pretrained(path)\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cbc6f13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_nli_model_path = join_path(dataset, 'scorer_model', 'keyword_scorer')\n",
    "abstract_nli_model_path = join_path(dataset, 'scorer_model', 'abstract_scorer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f52748e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBERT embeddings (precomputed for efficiency)\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sbert_embeddings = [\n",
    "    sbert_model.encode(keywords, convert_to_numpy=True),\n",
    "    sbert_model.encode(abstract_concepts, convert_to_numpy=True),\n",
    "    sbert_model.encode(labels, convert_to_numpy=True)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "549abd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "concept_names = [keywords, abstract_concepts, labels]\n",
    "model = ConceptNetwork(\n",
    "    concept_names, embedding_dim=64, \n",
    "    keyword_nli_model_path=keyword_nli_model_path,\n",
    "    abstract_nli_model_path=abstract_nli_model_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dfd6fddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.utils import logging\n",
    "\n",
    "logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99983eb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 4/4 [00:35<00:00,  8.76s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 2.1116, Val Loss: 1.3244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 4/4 [00:38<00:00,  9.57s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2, Train Loss: 2.0388, Val Loss: 1.3118\n"
     ]
    }
   ],
   "source": [
    "# Train\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "train_losses, val_losses = train_model(\n",
    "    model, train_texts, train_labels, val_texts, val_labels,\n",
    "    concept_names, sbert_embeddings, batch_size=16, num_epochs=20,\n",
    "    patience=5, lambda_semantic=0.1, device=device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "37f159be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6fac4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "                                 precision    recall  f1-score   support\n",
      "\n",
      "        cardiovascular diseases       0.00      0.00      0.00         1\n",
      "      digestive system diseases       0.00      0.00      0.00         1\n",
      "general pathological conditions       0.20      1.00      0.33         1\n",
      "                      neoplasms       0.00      0.00      0.00         1\n",
      "        nervous system diseases       0.00      0.00      0.00         1\n",
      "\n",
      "                       accuracy                           0.20         5\n",
      "                      macro avg       0.04      0.20      0.07         5\n",
      "                   weighted avg       0.04      0.20      0.07         5\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dauduchieu/Desktop/iSE-CBM/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/dauduchieu/Desktop/iSE-CBM/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n",
      "/Users/dauduchieu/Desktop/iSE-CBM/venv/lib/python3.13/site-packages/sklearn/metrics/_classification.py:1706: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", result.shape[0])\n"
     ]
    }
   ],
   "source": [
    "test_model(model, test_texts, test_labels, concept_names, batch_size=16, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "260cb781",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpretable Prediction for Sample:\n",
      "Input Text: Plasma concentrations of epinephrine during CPR in the dog. STUDY OBJECTIVE: The purpose of this study was to evaluate whether the marked increase in the plasma concentrations of epinephrine during cardiopulmonary arrest and basic life support (BLS) could be due in part to decreased distribution and/or elimination. DESIGN AND INTERVENTIONS: Dogs were randomly assigned to undergo adrenalectomy or sham-operation. Some adrenalectomized animals received an epinephrine infusion. MEASUREMENTS AND MAIN RESULTS: In the seven sham-operated dogs, the plasma epinephrine concentrations increased markedly during BLS as expected. In the seven adrenalectomized dogs receiving a constant infusion of epinephrine, cardiopulmonary arrest and BLS induced a three to sixfold increase in plasma epinephrine concentrations, with an increase in the mean plasma epinephrine concentrations (calculated from the area under the curve) of 1.21 +/- 0.12 ng/mL (P less than .05). In the seven adrenalectomized dogs receiving a constant epinephrine infusion but not subjected to cardiopulmonary arrest, the plasma epinephrine concentrations remained stable. Finally, in the seven adrenalectomized dogs not receiving an epinephrine infusion, the mean plasma epinephrine concentrations during BLS (calculated from the area under the curve) increased only by 0.05 +/- 0.04 ng/mL, significantly less than in adrenalectomized dogs receiving an epinephrine infusion (P less than .01). CONCLUSION: The increase in plasma epinephrine concentrations during cardiopulmonary arrest and BLS is due in part to an altered disposition of epinephrine. \n",
      "True Label: cardiovascular diseases\n",
      "\n",
      "Keyword Layer Activations:\n",
      "  coronary: 0.5099\n",
      "  myocardial: 0.5118\n",
      "  hypertension: 0.5139\n",
      "  cardiac: 0.4982\n",
      "  systolic: 0.4195\n",
      "  colitis: 0.5269\n",
      "  esophageal: 0.4869\n",
      "  gastrointestinal: 0.5135\n",
      "  bowel: 0.5083\n",
      "  duodenal: 0.5052\n",
      "  defect: 0.5147\n",
      "  loss: 0.5184\n",
      "  airway: 0.5185\n",
      "  graft: 0.5049\n",
      "  respiratory: 0.5004\n",
      "  cancer: 0.5012\n",
      "  carcinoma: 0.4992\n",
      "  sarcoma: 0.5168\n",
      "  malignancy: 0.4569\n",
      "  chemotherapy: 0.5198\n",
      "  brain: 0.5037\n",
      "  cerebral: 0.5457\n",
      "  neuronal: 0.5045\n",
      "  motor: 0.5270\n",
      "  cord: 0.4998\n",
      "\n",
      "Abstract Layer Activations:\n",
      "  Cardiac Function and Disorders: 0.6692\n",
      "  Heart Muscle and Blood Pressure: 0.6345\n",
      "  Coronary Artery Issues: 0.6547\n",
      "  Intestinal and Esophageal Conditions: 0.6226\n",
      "  Gastrointestinal Tract Ailments: 0.6368\n",
      "  Inflammatory Bowel Diseases: 0.6285\n",
      "  General Pathological States: 0.6480\n",
      "  Respiratory System Impairments: 0.6255\n",
      "  Tissue and Graft Issues: 0.6304\n",
      "  Malignant Tumors and Growths: 0.6223\n",
      "  Cancer Treatment and Types: 0.4591\n",
      "  Oncological Malignancies: 0.5680\n",
      "  Central and Peripheral Nervous System Disorders: 0.6027\n",
      "  Brain and Cerebral Conditions: 0.6333\n",
      "  Spinal Cord and Motor Function Impairment: 0.6436\n",
      "\n",
      "Label Layer Probabilities:\n",
      "  cardiovascular diseases: 0.1090\n",
      "  digestive system diseases: 0.1776\n",
      "  general pathological conditions: 0.2900\n",
      "  neoplasms: 0.2391\n",
      "  nervous system diseases: 0.1843\n",
      "\n",
      "Predicted Label: general pathological conditions\n"
     ]
    }
   ],
   "source": [
    "# Interpretable prediction and visualization for a single sample\n",
    "if test_texts and test_labels:\n",
    "    keyword_scores, abstract_scores, label_probs, predicted_label_idx = interpretable_prediction(\n",
    "        model, test_texts[0], test_labels[0], concept_names, device=device\n",
    "    )\n",
    "    visualize_network(model, concept_names, keyword_scores, abstract_scores, label_probs, predicted_label_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb13b4fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
