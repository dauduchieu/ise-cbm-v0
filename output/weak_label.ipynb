{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29577d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.451132Z",
     "iopub.status.busy": "2025-07-13T16:31:10.450970Z",
     "iopub.status.idle": "2025-07-13T16:31:10.453278Z",
     "shell.execute_reply": "2025-07-13T16:31:10.453054Z"
    },
    "papermill": {
     "duration": 0.006587,
     "end_time": "2025-07-13T16:31:10.454356",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.447769",
     "status": "completed"
    },
    "tags": [
     "injected-parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "test = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eeeec6aa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.458624Z",
     "iopub.status.busy": "2025-07-13T16:31:10.458395Z",
     "iopub.status.idle": "2025-07-13T16:31:10.460326Z",
     "shell.execute_reply": "2025-07-13T16:31:10.460060Z"
    },
    "papermill": {
     "duration": 0.004835,
     "end_time": "2025-07-13T16:31:10.461293",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.456458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Param\n",
    "# test = \"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b7bd17c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.466044Z",
     "iopub.status.busy": "2025-07-13T16:31:10.465853Z",
     "iopub.status.idle": "2025-07-13T16:31:10.467494Z",
     "shell.execute_reply": "2025-07-13T16:31:10.467283Z"
    },
    "papermill": {
     "duration": 0.004494,
     "end_time": "2025-07-13T16:31:10.468218",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.463724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_test = True\n",
    "if test == \"False\" or test == False:\n",
    "    is_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea736f0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.471977Z",
     "iopub.status.busy": "2025-07-13T16:31:10.471875Z",
     "iopub.status.idle": "2025-07-13T16:31:10.473751Z",
     "shell.execute_reply": "2025-07-13T16:31:10.473510Z"
    },
    "papermill": {
     "duration": 0.004559,
     "end_time": "2025-07-13T16:31:10.474507",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.469948",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dauduchieu/Documents/iSE2025/CBM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d3c22b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.478865Z",
     "iopub.status.busy": "2025-07-13T16:31:10.478747Z",
     "iopub.status.idle": "2025-07-13T16:31:10.480700Z",
     "shell.execute_reply": "2025-07-13T16:31:10.480470Z"
    },
    "papermill": {
     "duration": 0.004887,
     "end_time": "2025-07-13T16:31:10.481351",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.476464",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "is_test = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d87ea712",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.485229Z",
     "iopub.status.busy": "2025-07-13T16:31:10.485123Z",
     "iopub.status.idle": "2025-07-13T16:31:10.486625Z",
     "shell.execute_reply": "2025-07-13T16:31:10.486412Z"
    },
    "papermill": {
     "duration": 0.004033,
     "end_time": "2025-07-13T16:31:10.487241",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.483208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Param\n",
    "dataset = 'data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23bd4e63",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.490794Z",
     "iopub.status.busy": "2025-07-13T16:31:10.490677Z",
     "iopub.status.idle": "2025-07-13T16:31:10.820161Z",
     "shell.execute_reply": "2025-07-13T16:31:10.819903Z"
    },
    "papermill": {
     "duration": 0.332119,
     "end_time": "2025-07-13T16:31:10.820982",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.488863",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b28869db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.824780Z",
     "iopub.status.busy": "2025-07-13T16:31:10.824659Z",
     "iopub.status.idle": "2025-07-13T16:31:10.826252Z",
     "shell.execute_reply": "2025-07-13T16:31:10.825989Z"
    },
    "papermill": {
     "duration": 0.004119,
     "end_time": "2025-07-13T16:31:10.826885",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.822766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "17b8455f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.830575Z",
     "iopub.status.busy": "2025-07-13T16:31:10.830402Z",
     "iopub.status.idle": "2025-07-13T16:31:10.904169Z",
     "shell.execute_reply": "2025-07-13T16:31:10.903923Z"
    },
    "papermill": {
     "duration": 0.076506,
     "end_time": "2025-07-13T16:31:10.905001",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.828495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = data_loader.get_data_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1758873",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.909135Z",
     "iopub.status.busy": "2025-07-13T16:31:10.909005Z",
     "iopub.status.idle": "2025-07-13T16:31:10.911019Z",
     "shell.execute_reply": "2025-07-13T16:31:10.910804Z"
    },
    "papermill": {
     "duration": 0.004838,
     "end_time": "2025-07-13T16:31:10.911643",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.906805",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_desc = data_loader.get_data_desc()\n",
    "label_column = data_desc['label_column']\n",
    "text_column = data_desc['text_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ad0a27c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.915299Z",
     "iopub.status.busy": "2025-07-13T16:31:10.915209Z",
     "iopub.status.idle": "2025-07-13T16:31:10.916854Z",
     "shell.execute_reply": "2025-07-13T16:31:10.916657Z"
    },
    "papermill": {
     "duration": 0.004102,
     "end_time": "2025-07-13T16:31:10.917440",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.913338",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keyword_concepts = data_loader.get_keyword_concepts()\n",
    "abstract_concepts = data_loader.get_abstract_concepts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b0ce3d4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.920883Z",
     "iopub.status.busy": "2025-07-13T16:31:10.920793Z",
     "iopub.status.idle": "2025-07-13T16:31:10.925943Z",
     "shell.execute_reply": "2025-07-13T16:31:10.925728Z"
    },
    "papermill": {
     "duration": 0.007562,
     "end_time": "2025-07-13T16:31:10.926575",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.919013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if is_test:\n",
    "    train_df = train_df.groupby(label_column).sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3a9a0b",
   "metadata": {
    "papermill": {
     "duration": 0.001548,
     "end_time": "2025-07-13T16:31:10.929813",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.928265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9cf9fdb9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:10.933291Z",
     "iopub.status.busy": "2025-07-13T16:31:10.933122Z",
     "iopub.status.idle": "2025-07-13T16:31:11.332018Z",
     "shell.execute_reply": "2025-07-13T16:31:11.331761Z"
    },
    "papermill": {
     "duration": 0.401738,
     "end_time": "2025-07-13T16:31:11.333049",
     "exception": false,
     "start_time": "2025-07-13T16:31:10.931311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "class LLMCaller(ABC):\n",
    "    @abstractmethod\n",
    "    def structed_output(self, prompt:str, output_struct):\n",
    "        pass\n",
    "\n",
    "from time import time, sleep\n",
    "from typing import List, Callable, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "class GeminiRateLimiter:\n",
    "    def __init__(self, requests_per_minute: int = 15):\n",
    "        self.rpm = requests_per_minute\n",
    "        self.times: List[float] = []\n",
    "\n",
    "    def wait(self):\n",
    "        now = time()\n",
    "        self.times = [t for t in self.times if now - t <= 60]\n",
    "        if len(self.times) >= self.rpm:\n",
    "            sleep(60 - (now - self.times[0]))\n",
    "            now = time()\n",
    "            self.times = [t for t in self.times if now - t <= 60]\n",
    "\n",
    "    def record(self):\n",
    "        self.times.append(time())\n",
    "\n",
    "    def execute(self, f: Callable[..., T], *args, **kwargs) -> T:\n",
    "        self.wait()\n",
    "        try:\n",
    "            r = f(*args, **kwargs)\n",
    "            self.record()\n",
    "            return r\n",
    "        except:\n",
    "            self.record()\n",
    "            raise\n",
    "\n",
    "    def __call__(self, f: Callable[..., T]) -> Callable[..., T]:\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return self.execute(f, *args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.wait()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.record()\n",
    "\n",
    "from google import genai\n",
    "\n",
    "class GeminiAPICaller(LLMCaller):\n",
    "    def __init__(self, api_key:str, api_model:str, api_rpm:int):\n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "        self.api_model = api_model\n",
    "        self.rate_limiter = GeminiRateLimiter(requests_per_minute=api_rpm)\n",
    "\n",
    "    def structed_output(self, prompt:str, output_struct):\n",
    "        with self.rate_limiter:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.api_model,\n",
    "                contents=prompt,\n",
    "                config={\n",
    "                    'response_mime_type': 'application/json',\n",
    "                    'response_schema': output_struct,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        res = response.parsed\n",
    "        return res\n",
    "    \n",
    "llm_api_config = data_loader.get_llm_config()\n",
    "\n",
    "llm_caller = GeminiAPICaller(\n",
    "    api_key=llm_api_config['api_key'],\n",
    "    api_model=llm_api_config['model'],\n",
    "    api_rpm=llm_api_config['rate_per_minute']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d08a4e54",
   "metadata": {
    "papermill": {
     "duration": 0.001636,
     "end_time": "2025-07-13T16:31:11.336631",
     "exception": false,
     "start_time": "2025-07-13T16:31:11.334995",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "711f6d6c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:11.340398Z",
     "iopub.status.busy": "2025-07-13T16:31:11.340286Z",
     "iopub.status.idle": "2025-07-13T16:31:12.811352Z",
     "shell.execute_reply": "2025-07-13T16:31:12.811022Z"
    },
    "papermill": {
     "duration": 1.47432,
     "end_time": "2025-07-13T16:31:12.812637",
     "exception": false,
     "start_time": "2025-07-13T16:31:11.338317",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49aa03f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:12.817276Z",
     "iopub.status.busy": "2025-07-13T16:31:12.817081Z",
     "iopub.status.idle": "2025-07-13T16:31:13.070236Z",
     "shell.execute_reply": "2025-07-13T16:31:13.069935Z"
    },
    "papermill": {
     "duration": 0.256214,
     "end_time": "2025-07-13T16:31:13.071124",
     "exception": false,
     "start_time": "2025-07-13T16:31:12.814910",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2d1aa0f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:13.075398Z",
     "iopub.status.busy": "2025-07-13T16:31:13.075280Z",
     "iopub.status.idle": "2025-07-13T16:31:21.010256Z",
     "shell.execute_reply": "2025-07-13T16:31:21.009844Z"
    },
    "papermill": {
     "duration": 7.937951,
     "end_time": "2025-07-13T16:31:21.011036",
     "exception": false,
     "start_time": "2025-07-13T16:31:13.073085",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:   0%|                                                                                                                                                    | 0/250 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:   2%|██▊                                                                                                                                         | 5/250 [00:00<00:06, 36.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:   4%|█████                                                                                                                                       | 9/250 [00:00<00:08, 29.09it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:   5%|██████▋                                                                                                                                    | 12/250 [00:00<00:08, 27.54it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:   6%|████████▉                                                                                                                                  | 16/250 [00:00<00:08, 26.96it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:   8%|██████████▌                                                                                                                                | 19/250 [00:00<00:08, 27.66it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:   9%|████████████▏                                                                                                                              | 22/250 [00:00<00:08, 27.93it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  10%|█████████████▉                                                                                                                             | 25/250 [00:00<00:08, 27.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  11%|███████████████▌                                                                                                                           | 28/250 [00:00<00:08, 27.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  13%|█████████████████▊                                                                                                                         | 32/250 [00:01<00:07, 30.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  15%|████████████████████▌                                                                                                                      | 37/250 [00:01<00:06, 32.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  16%|██████████████████████▊                                                                                                                    | 41/250 [00:01<00:06, 32.10it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  18%|█████████████████████████                                                                                                                  | 45/250 [00:01<00:06, 30.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  20%|███████████████████████████▏                                                                                                               | 49/250 [00:01<00:07, 28.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  21%|████████████████████████████▉                                                                                                              | 52/250 [00:01<00:07, 26.51it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  22%|███████████████████████████████▏                                                                                                           | 56/250 [00:01<00:06, 27.97it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  24%|█████████████████████████████████▎                                                                                                         | 60/250 [00:02<00:06, 27.44it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  26%|███████████████████████████████████▌                                                                                                       | 64/250 [00:02<00:06, 29.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  27%|█████████████████████████████████████▊                                                                                                     | 68/250 [00:02<00:06, 28.85it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  29%|████████████████████████████████████████▌                                                                                                  | 73/250 [00:02<00:05, 32.99it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  31%|██████████████████████████████████████████▊                                                                                                | 77/250 [00:02<00:05, 31.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  33%|█████████████████████████████████████████████▌                                                                                             | 82/250 [00:02<00:04, 35.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  34%|███████████████████████████████████████████████▊                                                                                           | 86/250 [00:02<00:04, 33.87it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  36%|██████████████████████████████████████████████████                                                                                         | 90/250 [00:02<00:04, 32.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  38%|████████████████████████████████████████████████████▎                                                                                      | 94/250 [00:03<00:04, 33.81it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  39%|██████████████████████████████████████████████████████▍                                                                                    | 98/250 [00:03<00:04, 31.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  41%|████████████████████████████████████████████████████████▎                                                                                 | 102/250 [00:03<00:04, 33.45it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  42%|██████████████████████████████████████████████████████████▌                                                                               | 106/250 [00:03<00:04, 30.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  44%|████████████████████████████████████████████████████████████▋                                                                             | 110/250 [00:03<00:04, 30.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  46%|██████████████████████████████████████████████████████████████▉                                                                           | 114/250 [00:03<00:04, 31.01it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  48%|█████████████████████████████████████████████████████████████████▋                                                                        | 119/250 [00:03<00:03, 35.32it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  49%|███████████████████████████████████████████████████████████████████▉                                                                      | 123/250 [00:04<00:04, 30.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  51%|██████████████████████████████████████████████████████████████████████                                                                    | 127/250 [00:04<00:03, 32.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  52%|████████████████████████████████████████████████████████████████████████▎                                                                 | 131/250 [00:04<00:03, 34.28it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  54%|███████████████████████████████████████████████████████████████████████████                                                               | 136/250 [00:04<00:03, 36.94it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  56%|█████████████████████████████████████████████████████████████████████████████▎                                                            | 140/250 [00:04<00:03, 32.60it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  58%|███████████████████████████████████████████████████████████████████████████████▍                                                          | 144/250 [00:04<00:03, 29.42it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  59%|█████████████████████████████████████████████████████████████████████████████████▋                                                        | 148/250 [00:04<00:03, 30.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  61%|███████████████████████████████████████████████████████████████████████████████████▉                                                      | 152/250 [00:04<00:03, 27.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  62%|█████████████████████████████████████████████████████████████████████████████████████▌                                                    | 155/250 [00:05<00:03, 27.86it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  64%|███████████████████████████████████████████████████████████████████████████████████████▊                                                  | 159/250 [00:05<00:02, 30.75it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  65%|█████████████████████████████████████████████████████████████████████████████████████████▉                                                | 163/250 [00:05<00:02, 32.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  67%|████████████████████████████████████████████████████████████████████████████████████████████▏                                             | 167/250 [00:05<00:02, 32.84it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  68%|██████████████████████████████████████████████████████████████████████████████████████████████▍                                           | 171/250 [00:05<00:02, 32.37it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  70%|████████████████████████████████████████████████████████████████████████████████████████████████▌                                         | 175/250 [00:05<00:02, 30.69it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  72%|██████████████████████████████████████████████████████████████████████████████████████████████████▊                                       | 179/250 [00:05<00:02, 31.38it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  73%|█████████████████████████████████████████████████████████████████████████████████████████████████████                                     | 183/250 [00:05<00:02, 29.43it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  75%|███████████████████████████████████████████████████████████████████████████████████████████████████████▏                                  | 187/250 [00:06<00:02, 31.18it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  76%|█████████████████████████████████████████████████████████████████████████████████████████████████████████▍                                | 191/250 [00:06<00:01, 31.16it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  78%|███████████████████████████████████████████████████████████████████████████████████████████████████████████▋                              | 195/250 [00:06<00:01, 32.36it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  80%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████▍                           | 200/250 [00:06<00:01, 35.72it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  82%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                         | 204/250 [00:06<00:01, 34.80it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  83%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊                       | 208/250 [00:06<00:01, 35.21it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  85%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌                    | 213/250 [00:06<00:00, 37.11it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  87%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▎                 | 218/250 [00:06<00:00, 39.02it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  89%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████               | 223/250 [00:06<00:00, 40.40it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  91%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊            | 228/250 [00:07<00:00, 37.88it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  93%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████          | 232/250 [00:07<00:00, 36.92it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  95%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊       | 237/250 [00:07<00:00, 39.82it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  97%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▌    | 242/250 [00:07<00:00, 34.56it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing:  98%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████▊  | 246/250 [00:07<00:00, 32.31it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:07<00:00, 28.27it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Lemmatizing: 100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 250/250 [00:07<00:00, 31.58it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tqdm.pandas(desc=\"Lemmatizing\")\n",
    "def lemmatize_text(text):\n",
    "    doc = nlp(text)\n",
    "    return ' '.join([token.lemma_ for token in doc])\n",
    "train_df['text_lemma'] = train_df[text_column].progress_apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b0faa608",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:21.017581Z",
     "iopub.status.busy": "2025-07-13T16:31:21.017455Z",
     "iopub.status.idle": "2025-07-13T16:31:21.019496Z",
     "shell.execute_reply": "2025-07-13T16:31:21.019304Z"
    },
    "papermill": {
     "duration": 0.005715,
     "end_time": "2025-07-13T16:31:21.020084",
     "exception": false,
     "start_time": "2025-07-13T16:31:21.014369",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hypertension', 'myocardial', 'infarction', 'ischemia', 'coronary', 'pancreatitis', 'ulcer', 'obstruction', 'biliary', 'bowel', 'deficiency', 'disorder', 'necrosis', 'oncogene', 'bone', 'tumor', 'carcinoma', 'adenocarcinoma', 'malignant', 'metastasis', 'neurologic', 'epilepsy', 'seizure', 'spinal', 'cord']\n"
     ]
    }
   ],
   "source": [
    "keywords = []\n",
    "for k in keyword_concepts.keys():\n",
    "    keywords += keyword_concepts[k]\n",
    "\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4e8799f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:21.025874Z",
     "iopub.status.busy": "2025-07-13T16:31:21.025782Z",
     "iopub.status.idle": "2025-07-13T16:31:21.027749Z",
     "shell.execute_reply": "2025-07-13T16:31:21.027564Z"
    },
    "papermill": {
     "duration": 0.00542,
     "end_time": "2025-07-13T16:31:21.028294",
     "exception": false,
     "start_time": "2025-07-13T16:31:21.022874",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def llm_get_synonyms(data_topic, keyword, n_syn=10):\n",
    "    prompt = f\"\"\"\n",
    "You are an expert in the {data_topic} domain.\n",
    "\n",
    "Please list {n_syn} synonyms or alternative expressions for the term: \"{keyword}\".\n",
    "\n",
    "The synonyms should be relevant to the {data_topic} context. If the term has multiple meanings, only return synonyms that are appropriate within this context.\n",
    "\n",
    "Only return a list of synonyms as an array of strings, no explanation.\n",
    "\"\"\"\n",
    "\n",
    "    output_struct = {\n",
    "        \"type\": \"array\",\n",
    "        \"items\": {\n",
    "            \"type\": \"string\"\n",
    "        }\n",
    "    }\n",
    "\n",
    "    synonyms = llm_caller.structed_output(\n",
    "        prompt=prompt.strip(),\n",
    "        output_struct=output_struct\n",
    "    )\n",
    "\n",
    "    synonyms = [lemmatize_text(t) for t in synonyms]\n",
    "\n",
    "    return synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "006aa021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:21.034745Z",
     "iopub.status.busy": "2025-07-13T16:31:21.034644Z",
     "iopub.status.idle": "2025-07-13T16:31:21.890375Z",
     "shell.execute_reply": "2025-07-13T16:31:21.890047Z"
    },
    "papermill": {
     "duration": 0.860108,
     "end_time": "2025-07-13T16:31:21.891637",
     "exception": false,
     "start_time": "2025-07-13T16:31:21.031529",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['high blood pressure', 'elevated blood pressure', 'arterial hypertension', 'essential hypertension', 'secondary hypertension']\n"
     ]
    }
   ],
   "source": [
    "print(llm_get_synonyms(\n",
    "    data_topic=data_desc['data_topic'],\n",
    "    keyword='hypertension',\n",
    "    n_syn=5\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8a9aedf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-13T16:31:21.898640Z",
     "iopub.status.busy": "2025-07-13T16:31:21.898506Z",
     "iopub.status.idle": "2025-07-13T16:32:53.983672Z",
     "shell.execute_reply": "2025-07-13T16:32:53.983142Z"
    },
    "papermill": {
     "duration": 91.909965,
     "end_time": "2025-07-13T16:32:53.805051",
     "exception": false,
     "start_time": "2025-07-13T16:31:21.895086",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:   0%|                                                                                                                                             | 0/25 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:   4%|█████▎                                                                                                                               | 1/25 [00:01<00:24,  1.04s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:   8%|██████████▋                                                                                                                          | 2/25 [00:01<00:20,  1.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  12%|███████████████▉                                                                                                                     | 3/25 [00:02<00:19,  1.15it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  16%|█████████████████████▎                                                                                                               | 4/25 [00:03<00:17,  1.22it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  20%|██████████████████████████▌                                                                                                          | 5/25 [00:06<00:33,  1.67s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  24%|███████████████████████████████▉                                                                                                     | 6/25 [00:07<00:24,  1.31s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  28%|█████████████████████████████████████▏                                                                                               | 7/25 [00:08<00:22,  1.22s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  32%|██████████████████████████████████████████▌                                                                                          | 8/25 [00:08<00:17,  1.06s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  36%|███████████████████████████████████████████████▉                                                                                     | 9/25 [00:10<00:17,  1.07s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  40%|████████████████████████████████████████████████████▊                                                                               | 10/25 [01:01<04:11, 16.75s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  44%|██████████████████████████████████████████████████████████                                                                          | 11/25 [01:02<02:46, 11.88s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  48%|███████████████████████████████████████████████████████████████▎                                                                    | 12/25 [01:03<01:49,  8.46s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  52%|████████████████████████████████████████████████████████████████████▋                                                               | 13/25 [01:04<01:14,  6.18s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  56%|█████████████████████████████████████████████████████████████████████████▉                                                          | 14/25 [01:04<00:49,  4.52s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  60%|███████████████████████████████████████████████████████████████████████████████▏                                                    | 15/25 [01:07<00:38,  3.82s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  64%|████████████████████████████████████████████████████████████████████████████████████▍                                               | 16/25 [01:08<00:26,  2.95s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  68%|█████████████████████████████████████████████████████████████████████████████████████████▊                                          | 17/25 [01:08<00:18,  2.29s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  72%|███████████████████████████████████████████████████████████████████████████████████████████████                                     | 18/25 [01:09<00:13,  1.93s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                               | 19/25 [01:10<00:09,  1.53s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Create synonym dict:  76%|████████████████████████████████████████████████████████████████████████████████████████████████████▎                               | 19/25 [01:31<00:29,  4.84s/it]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m kw_synonym_dict = {}\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m kw \u001b[38;5;129;01min\u001b[39;00m tqdm(keywords, total=\u001b[38;5;28mlen\u001b[39m(keywords), desc=\u001b[33m\"\u001b[39m\u001b[33mCreate synonym dict\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     llm_syn = \u001b[43mllm_get_synonyms\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_topic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_desc\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdata_topic\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_syn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     llm_syn = [lemmatize_text(s) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m llm_syn]\n\u001b[32m      5\u001b[39m     kw_synonym_dict.update({\n\u001b[32m      6\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkw\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m: [kw] + llm_syn\n\u001b[32m      7\u001b[39m     })\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mllm_get_synonyms\u001b[39m\u001b[34m(data_topic, keyword, n_syn)\u001b[39m\n\u001b[32m      2\u001b[39m     prompt = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[33mYou are an expert in the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata_topic\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m domain.\u001b[39m\n\u001b[32m      4\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m      9\u001b[39m \u001b[33mOnly return a list of synonyms as an array of strings, no explanation.\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m     12\u001b[39m     output_struct = {\n\u001b[32m     13\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mitems\u001b[39m\u001b[33m\"\u001b[39m: {\n\u001b[32m     15\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mtype\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mstring\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     16\u001b[39m         }\n\u001b[32m     17\u001b[39m     }\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     synonyms = \u001b[43mllm_caller\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstructed_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrip\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43moutput_struct\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_struct\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m     synonyms = [lemmatize_text(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m synonyms]\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m synonyms\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36mGeminiAPICaller.structed_output\u001b[39m\u001b[34m(self, prompt, output_struct)\u001b[39m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mstructed_output\u001b[39m(\u001b[38;5;28mself\u001b[39m, prompt:\u001b[38;5;28mstr\u001b[39m, output_struct):\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrate_limiter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     60\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapi_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     62\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcontents\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     69\u001b[39m     res = response.parsed\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mGeminiRateLimiter.__enter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mGeminiRateLimiter.wait\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     19\u001b[39m \u001b[38;5;28mself\u001b[39m.times = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.times \u001b[38;5;28;01mif\u001b[39;00m now - t <= \u001b[32m60\u001b[39m]\n\u001b[32m     20\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.times) >= \u001b[38;5;28mself\u001b[39m.rpm:\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m     \u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mnow\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimes\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m     now = time()\n\u001b[32m     23\u001b[39m     \u001b[38;5;28mself\u001b[39m.times = [t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.times \u001b[38;5;28;01mif\u001b[39;00m now - t <= \u001b[32m60\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "kw_synonym_dict = {}\n",
    "for kw in tqdm(keywords, total=len(keywords), desc=\"Create synonym dict\"):\n",
    "    llm_syn = llm_get_synonyms(data_topic=data_desc['data_topic'], keyword=kw, n_syn=5)\n",
    "    llm_syn = [lemmatize_text(s) for s in llm_syn]\n",
    "    kw_synonym_dict.update({\n",
    "        f\"{kw}\": [kw] + llm_syn\n",
    "    })\n",
    "\n",
    "print(kw_synonym_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049c86d7",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "texts = train_df['text_lemma']\n",
    "print(len(texts))\n",
    "print(keywords)\n",
    "print(kw_synonym_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74659af",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def keyword_presence_matrix_from_df(df, keywords, kw_synonym_dict,\n",
    "                                    text_col='text_column', lemma_col='text_lemma'):\n",
    "    results = []\n",
    "\n",
    "    for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Keyword weak labeling\"):\n",
    "        original_text = row[text_col]\n",
    "        lemmatized_text = row[lemma_col]\n",
    "\n",
    "        for kw in keywords:\n",
    "            syns = kw_synonym_dict.get(kw, [])\n",
    "            all_terms = [kw] + syns\n",
    "            score = int(any(term in lemmatized_text for term in all_terms))\n",
    "            results.append((original_text, kw, score))\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\"text\", \"keyword\", \"score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95524796",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kw_wl_df = keyword_presence_matrix_from_df(train_df, keywords, kw_synonym_dict, text_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7b6171",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kw_wl_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a52f47e5",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "kw_wl_df.value_counts('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93db72ec",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(abstract_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2fcc94",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def aggregate_full_concept_matrix(wl_df, abstract_concepts):\n",
    "    # Lọc score == 1 trong wl_df để dễ truy cập\n",
    "    matched = wl_df[wl_df['score'] == 1]\n",
    "\n",
    "    # Tạo set {(text, keyword)} đã match\n",
    "    matched_pairs = set(zip(matched['text'], matched['keyword']))\n",
    "\n",
    "    # Lấy danh sách unique texts\n",
    "    texts = wl_df['text'].unique()\n",
    "\n",
    "    # Kết quả\n",
    "    results = []\n",
    "\n",
    "    for text in tqdm(texts, total=len(texts), desc=\"Abstract concept weak labeling\"):\n",
    "        for concept in abstract_concepts:\n",
    "            concept_name = concept['abstract_concept_name']\n",
    "            concept_keywords = concept['keywords']\n",
    "\n",
    "            # Nếu có ít nhất một keyword trong concept xuất hiện trong matched_pairs → score = 1\n",
    "            score = int(any((text, kw) in matched_pairs for kw in concept_keywords))\n",
    "\n",
    "            results.append((text, concept_name, score))\n",
    "\n",
    "    return pd.DataFrame(results, columns=[\"text\", \"abstract_concept\", \"score\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bef309",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "abstract_df = aggregate_full_concept_matrix(kw_wl_df, abstract_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdbe1d6c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "abstract_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "408a1063",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "abstract_df.value_counts('score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe07e723",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from utils.data_io import join_path, save_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "074d74c9",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_csv(kw_wl_df, dir=join_path(dataset, 'weak_label_data'), file_name='keyword_wl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0890309b",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "save_csv(abstract_df, dir=join_path(dataset, 'weak_label_data'), file_name='abstract_wl.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74091cb",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 105.191717,
   "end_time": "2025-07-13T16:32:54.752201",
   "environment_variables": {},
   "exception": null,
   "input_path": "weak_label.ipynb",
   "output_path": "output/weak_label.ipynb",
   "parameters": {
    "test": true
   },
   "start_time": "2025-07-13T16:31:09.560484",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}