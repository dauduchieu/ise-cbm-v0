{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ed177f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Param\n",
    "# test = \"False\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "431bf86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0d9813",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_io import join_path\n",
    "\n",
    "log_path = 'log.txt'\n",
    "\n",
    "def reset_file(path):\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        pass\n",
    "\n",
    "def add_line(path, content):\n",
    "    with open(path, \"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(content + \"\\n\")\n",
    "\n",
    "add_line(log_path, \"\")\n",
    "add_line(log_path, \"2. concept generating\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cfba86b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dauduchieu/Documents/iSE2025/CBM\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b33120e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_test = True\n",
    "if test == \"False\" or test == False:\n",
    "    is_test = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "51e387e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_loader import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "67004985",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bb3848b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = data_loader.get_data_train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5cbbf0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_desc = data_loader.get_data_desc()\n",
    "label_column = data_desc['label_column']\n",
    "text_column = data_desc['text_column']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cbd55a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['general pathological conditions', 'neoplasms',\n",
       "       'digestive system diseases', 'nervous system diseases',\n",
       "       'cardiovascular diseases'], dtype=object)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_df[label_column].unique()\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6e7770a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_test:\n",
    "    train_df = train_df.groupby(label_column).sample(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9ed0c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "043d697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "class LLMCaller(ABC):\n",
    "    @abstractmethod\n",
    "    def structed_output(self, prompt:str, output_struct):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "09b00c71",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import time, sleep\n",
    "from typing import List, Callable, TypeVar\n",
    "\n",
    "T = TypeVar('T')\n",
    "\n",
    "class GeminiRateLimiter:\n",
    "    def __init__(self, requests_per_minute: int = 15):\n",
    "        self.rpm = requests_per_minute\n",
    "        self.times: List[float] = []\n",
    "\n",
    "    def wait(self):\n",
    "        now = time()\n",
    "        self.times = [t for t in self.times if now - t <= 60]\n",
    "        if len(self.times) >= self.rpm:\n",
    "            sleep(60 - (now - self.times[0]))\n",
    "            now = time()\n",
    "            self.times = [t for t in self.times if now - t <= 60]\n",
    "\n",
    "    def record(self):\n",
    "        self.times.append(time())\n",
    "\n",
    "    def execute(self, f: Callable[..., T], *args, **kwargs) -> T:\n",
    "        self.wait()\n",
    "        try:\n",
    "            r = f(*args, **kwargs)\n",
    "            self.record()\n",
    "            return r\n",
    "        except:\n",
    "            self.record()\n",
    "            raise\n",
    "\n",
    "    def __call__(self, f: Callable[..., T]) -> Callable[..., T]:\n",
    "        def wrapper(*args, **kwargs):\n",
    "            return self.execute(f, *args, **kwargs)\n",
    "        return wrapper\n",
    "\n",
    "    def __enter__(self):\n",
    "        self.wait()\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, *args):\n",
    "        self.record()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76a92fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai\n",
    "\n",
    "class GeminiAPICaller(LLMCaller):\n",
    "    def __init__(self, api_key:str, api_model:str, api_rpm:int):\n",
    "        self.client = genai.Client(api_key=api_key)\n",
    "        self.api_model = api_model\n",
    "        self.rate_limiter = GeminiRateLimiter(requests_per_minute=api_rpm)\n",
    "\n",
    "    def structed_output(self, prompt:str, output_struct):\n",
    "        with self.rate_limiter:\n",
    "            response = self.client.models.generate_content(\n",
    "                model=self.api_model,\n",
    "                contents=prompt,\n",
    "                config={\n",
    "                    'response_mime_type': 'application/json',\n",
    "                    'response_schema': output_struct,\n",
    "                },\n",
    "            )\n",
    "\n",
    "        res = response.parsed\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62446957",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_api_config = data_loader.get_llm_config()\n",
    "\n",
    "llm_caller = GeminiAPICaller(\n",
    "    api_key=llm_api_config['api_key'],\n",
    "    api_model=llm_api_config['model'],\n",
    "    api_rpm=llm_api_config['rate_per_minute']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b64417",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "267f9f4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import spacy\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "449f9892",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "adf21784",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_custom_candidates(text, use_pos=True, pos_list=None, use_ner=True, use_chunks=True):\n",
    "    doc = nlp(text)\n",
    "    candidates = []\n",
    "\n",
    "    if use_pos:\n",
    "        if pos_list is None:\n",
    "            pos_list = [\"NOUN\", \"PROPN\", \"ADJ\"]\n",
    "        for token in doc:\n",
    "            if token.pos_ in pos_list and not token.is_stop and token.is_alpha:\n",
    "                candidates.append(token.lemma_.lower())\n",
    "\n",
    "    if use_ner:\n",
    "        for ent in doc.ents:\n",
    "            lemmatized_ent_tokens = [token.lemma_.lower() for token in nlp(ent.text)]\n",
    "            candidates.append(\" \".join(lemmatized_ent_tokens))\n",
    "\n",
    "    if use_chunks:\n",
    "        for chunk in doc.noun_chunks:\n",
    "            lemmatized_chunk_tokens = [token.lemma_.lower() for token in chunk if not token.is_stop and token.is_alpha]\n",
    "            chunk_text = \" \".join(lemmatized_chunk_tokens).strip()\n",
    "            if chunk_text:\n",
    "                candidates.append(chunk_text)\n",
    "\n",
    "    return candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2c5f1e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords_with_df_ilf(df, text_column, label_column, top_n=15,\n",
    "    use_pos=True, pos_list=None, use_ner=True, use_chunks=True, smooth=True,\n",
    "    threshold=0.02\n",
    "):\n",
    "    df = df.copy()\n",
    "    labels = df[label_column].unique()\n",
    "    num_labels = len(labels)\n",
    "\n",
    "    doc_freq_by_label = defaultdict(lambda: defaultdict(int))  # DF\n",
    "    label_counts = defaultdict(int)\n",
    "\n",
    "    for label in labels:\n",
    "        texts = df[df[label_column] == label][text_column].astype(str).tolist()\n",
    "        label_counts[label] = len(texts)\n",
    "\n",
    "        for text in tqdm(texts, total=len(texts), desc=f\"Label: {label}\"):\n",
    "            candidates = extract_custom_candidates(\n",
    "                text, use_pos=use_pos, pos_list=pos_list,\n",
    "                use_ner=use_ner, use_chunks=use_chunks\n",
    "            )\n",
    "            unique_terms = set(candidates)\n",
    "            for term in unique_terms:\n",
    "                doc_freq_by_label[label][term] += 1\n",
    "\n",
    "    all_terms = set(term for label_terms in doc_freq_by_label.values() for term in label_terms)\n",
    "    ilf_scores = defaultdict(float)\n",
    "\n",
    "    # ILF\n",
    "    for term in all_terms:\n",
    "        label_occurrences = sum(\n",
    "            1 for label in labels\n",
    "            if (doc_freq_by_label[label][term] / label_counts[label]) > threshold\n",
    "        )\n",
    "        ilf_scores[term] = np.log(num_labels / label_occurrences) if label_occurrences > 0 else 0\n",
    "\n",
    "    ranked_keywords_per_label = defaultdict(list)\n",
    "\n",
    "    for label in labels:\n",
    "        keyword_scores = {}\n",
    "        for term, df_val in doc_freq_by_label[label].items():\n",
    "            normalized_df = df_val / label_counts[label]\n",
    "            df_score = np.log(1 + normalized_df) if smooth else normalized_df\n",
    "            keyword_scores[term] = df_score * ilf_scores[term]\n",
    "        sorted_keywords = sorted(keyword_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "        ranked_keywords_per_label[label] = [kw for kw, score in sorted_keywords[:top_n]]\n",
    "\n",
    "    return ranked_keywords_per_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a04ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_line(log_path, \"keyword extracting\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4c3a9f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Label: general pathological conditions: 100%|██████████| 2268/2268 [01:12<00:00, 31.46it/s]\n",
      "Label: neoplasms: 100%|██████████| 1890/1890 [00:57<00:00, 32.87it/s]\n",
      "Label: digestive system diseases: 100%|██████████| 682/682 [00:22<00:00, 30.42it/s]\n",
      "Label: nervous system diseases: 100%|██████████| 926/926 [00:26<00:00, 35.19it/s]\n",
      "Label: cardiovascular diseases: 100%|██████████| 1723/1723 [01:01<00:00, 27.90it/s]\n"
     ]
    }
   ],
   "source": [
    "keywords = extract_keywords_with_df_ilf(\n",
    "    df=train_df,\n",
    "    text_column=text_column,\n",
    "    label_column=label_column,\n",
    "    top_n=10,\n",
    "    use_pos=True,\n",
    "    pos_list=[\"NOUN\", \"PROPN\", \"ADJ\"],\n",
    "    use_ner=False,\n",
    "    use_chunks=True,\n",
    "    threshold=0.02\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "56df06da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'general pathological conditions': ['hemorrhage', 'cardiac', 'respiratory', 'inflammatory', 'post', 'graft', 'pregnancy', 'airway', 'unknown', 'growth'], 'neoplasms': ['carcinoma', 'metastasis', 'chemotherapy', 'cancer', 'breast', 'node', 'metastatic', 'malignant', 'malignancy', 'radiation'], 'digestive system diseases': ['bowel', 'gastrointestinal', 'biliary', 'cirrhosis', 'bile', 'endoscopic', 'esophageal', 'gallbladder', 'ulcer', 'intestinal'], 'nervous system diseases': ['seizure', 'spinal', 'neurologic', 'deficit', 'nerve', 'nervous', 'cord', 'headache', 'movement', 'cognitive'], 'cardiovascular diseases': ['coronary', 'ventricular', 'cardiac', 'myocardial', 'systolic', 'hypertensive', 'blood pressure', 'diastolic', 'hemodynamic', 'heart']}\n"
     ]
    }
   ],
   "source": [
    "keywords = dict(keywords)\n",
    "print(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0b3187",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c1bcc53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_filter_keyword_concepts(keyword_concepts, data_topic, n_concepts=5):\n",
    "    \"\"\"\n",
    "    Filter keyword concepts for each label with additional context of keywords from other labels.\n",
    "    \n",
    "    Args:\n",
    "        keyword_concepts (dict): Mapping from label name to a list of raw keywords.\n",
    "        data_topic (str): The domain context (e.g., 'biomedical research abstracts').\n",
    "        n_concepts (int): Number of keywords to keep per label.\n",
    "\n",
    "    Returns:\n",
    "        dict: Mapping from label name to list of filtered keywords.\n",
    "    \"\"\"\n",
    "    filtered_keywords_by_label = {}\n",
    "    all_labels = list(keyword_concepts.keys())\n",
    "\n",
    "    for target_label in all_labels:\n",
    "        target_keywords = keyword_concepts[target_label]\n",
    "        keyword_list = \", \".join(target_keywords)\n",
    "\n",
    "        # Add reference keywords from other labels\n",
    "        competing_info = \"\"\n",
    "        for other_label in all_labels:\n",
    "            if other_label == target_label:\n",
    "                continue\n",
    "            other_keywords = keyword_concepts[other_label]\n",
    "            other_kw_str = \", \".join(other_keywords)\n",
    "            competing_info += f'- {other_label}: {other_kw_str}\\n'\n",
    "\n",
    "        # Construct prompt\n",
    "        prompt = f\"\"\"\n",
    "You are a domain expert working on the topic: \"{data_topic}\".\n",
    "\n",
    "Your task is to select the top {n_concepts} most meaningful and representative terms for the category \"{target_label}\".\n",
    "\n",
    "---\n",
    "\n",
    "### CATEGORY:\n",
    "\"{target_label}\"\n",
    "\n",
    "### RAW EXTRACTED KEYWORDS:\n",
    "{keyword_list}\n",
    "\n",
    "---\n",
    "\n",
    "### REFERENCE KEYWORDS FROM OTHER CATEGORIES:\n",
    "(These are keywords from competing labels. Use them to ensure your selections are distinctive.)\n",
    "\n",
    "{competing_info}\n",
    "\n",
    "---\n",
    "\n",
    "### INSTRUCTIONS:\n",
    "- Select exactly {n_concepts} keywords from the provided list under RAW EXTRACTED KEYWORDS.\n",
    "- Chosen terms should:\n",
    "  - Be highly relevant and representative of the target category\n",
    "  - Clearly distinguish the target category from others\n",
    "  - Be specific, unambiguous, and non-generic\n",
    "\n",
    "Avoid:\n",
    "- Generic terms (e.g., \"thing\", \"aspect\", \"problem\")\n",
    "- Redundant or overlapping words\n",
    "- Keywords similar to those in other categories\n",
    "\n",
    "Return your answer as a JSON object in the format:\n",
    "{{ \"{target_label}\": [\"keyword1\", \"keyword2\", ...] }}\n",
    "\"\"\".strip()\n",
    "\n",
    "        output_struct = {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                target_label: {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"string\"\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            \"required\": [target_label]\n",
    "        }\n",
    "\n",
    "        result = llm_caller.structed_output(prompt=prompt, output_struct=output_struct)\n",
    "        filtered_keywords_by_label[target_label] = result.get(target_label, [])\n",
    "\n",
    "    return filtered_keywords_by_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ce0d70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword_concepts = llm_filter_keyword_concepts(keywords, data_desc['data_topic'], n_concepts=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8f0f75cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'general pathological conditions': ['hemorrhage',\n",
       "  'inflammatory',\n",
       "  'growth',\n",
       "  'pregnancy',\n",
       "  'airway'],\n",
       " 'neoplasms': ['carcinoma',\n",
       "  'metastasis',\n",
       "  'chemotherapy',\n",
       "  'cancer',\n",
       "  'malignancy'],\n",
       " 'digestive system diseases': ['gastrointestinal',\n",
       "  'biliary',\n",
       "  'cirrhosis',\n",
       "  'esophageal',\n",
       "  'ulcer'],\n",
       " 'nervous system diseases': ['seizure',\n",
       "  'neurologic',\n",
       "  'nerve',\n",
       "  'spinal cord',\n",
       "  'cognitive'],\n",
       " 'cardiovascular diseases': ['coronary',\n",
       "  'ventricular',\n",
       "  'myocardial',\n",
       "  'hypertensive',\n",
       "  'hemodynamic']}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keyword_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9e68bb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def abstract_concept_prompt(\n",
    "    data_topic,\n",
    "    text_column,\n",
    "    label_column,\n",
    "    text_description,\n",
    "    label_description,\n",
    "    label_concepts,\n",
    "    keyword_concepts,\n",
    "    concepts_per_label=3\n",
    "):\n",
    "    label_concepts = [str(l) for l in label_concepts]\n",
    "    label_concepts_str = \"\\n- \" + \"\\n- \".join(label_concepts)\n",
    "\n",
    "    keyword_list_str = \"\"\n",
    "    for label, keywords in keyword_concepts.items():\n",
    "        for kw in keywords:\n",
    "            keyword_list_str += f\"- Keyword: \\\"{kw}\\\", Label: \\\"{label}\\\"\\n\"\n",
    "\n",
    "    total_labels = len(label_concepts)\n",
    "    total_concepts = total_labels * concepts_per_label\n",
    "\n",
    "    constraint_instruction = (\n",
    "        f\"- For each label, you must generate exactly {concepts_per_label} distinct and meaningful abstract concepts.\\n\"\n",
    "        f\"- The final list must contain exactly {total_concepts} abstract concept objects in total.\\n\"\n",
    "        \"- Each abstract concept object must include the \\\"label\\\" field indicating its corresponding label.\"\n",
    "    )\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "Data context:\n",
    "\n",
    "- Data topic: {data_topic}\n",
    "- Text column description: {text_description}\n",
    "- Label column description: {label_description}\n",
    "\n",
    "Input:\n",
    "\n",
    "- List of label concepts in the dataset: {label_concepts_str}\n",
    "\n",
    "- List of extracted keyword concepts, each associated with a label:\n",
    "{keyword_list_str}\n",
    "\n",
    "Important instructions:\n",
    "\n",
    "- For each label, generate exactly {concepts_per_label} abstract concepts.\n",
    "- That means the final JSON array must contain exactly {total_concepts} abstract concept objects.\n",
    "- Do not exceed or go below the required number of concepts per label.\n",
    "- A keyword can belong to multiple abstract concepts if semantically appropriate.\n",
    "- Likewise, an abstract concept can contain multiple keywords.\n",
    "- Abstract concepts must act as meaningful intermediate concepts between keywords and labels.\n",
    "- Abstract concepts must be:\n",
    "  - More specific than the label concept.\n",
    "  - More general and meaningful than individual keywords.\n",
    "  - They should never simply repeat or copy the label names.\n",
    "\n",
    "{constraint_instruction}\n",
    "\n",
    "Your task:\n",
    "\n",
    "- Group the provided keywords into abstract, higher-level concepts.\n",
    "- Each abstract concept object must:\n",
    "  - Have a clear, concise, and meaningful \"abstract_concept_name\" relevant to the {data_topic} domain (cannot be identical to the label).\n",
    "  - Include an optional short \"description\" (1-2 sentences).\n",
    "  - Include a \"keywords\" list of related keywords.\n",
    "  - Include the \"label\" field specifying the corresponding label.\n",
    "\n",
    "Expected output:\n",
    "\n",
    "- A valid JSON array.\n",
    "- Each item in the array must be an object with:\n",
    "  - \"abstract_concept_name\": string\n",
    "  - \"description\": string (optional)\n",
    "  - \"keywords\": array of strings\n",
    "  - \"label\": one of the provided label concepts\n",
    "\n",
    "Note: Only return valid JSON. Do not add explanations, comments, or extra text.\n",
    "\"\"\".strip()\n",
    "\n",
    "    return prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0a85d414",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract_prompt = abstract_concept_prompt(\n",
    "    data_topic=data_desc['data_topic'],\n",
    "    text_column=data_desc['text_column'],\n",
    "    label_column=data_desc['label_column'],\n",
    "    text_description=data_desc['text_description'],\n",
    "    label_description=data_desc['label_description'],\n",
    "    label_concepts=labels,\n",
    "    keyword_concepts=keyword_concepts,\n",
    "    concepts_per_label=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c86ff6e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_struct = {\n",
    "    \"type\": \"array\",\n",
    "    \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"properties\": {\n",
    "            \"abstract_concept_name\": {\"type\": \"string\"},\n",
    "            \"description\": {\"type\": \"string\"},\n",
    "            \"keywords\": {\n",
    "                \"type\": \"array\",\n",
    "                \"items\": {\"type\": \"string\"}\n",
    "            },\n",
    "            \"label\": {\"type\": \"string\"}\n",
    "        },\n",
    "        \"required\": [\"abstract_concept_name\", \"keywords\", \"label\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88a12aba",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'llm_caller' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m abstract_concepts = \u001b[43mllm_caller\u001b[49m.structed_output(\n\u001b[32m      2\u001b[39m     prompt=abstract_prompt,\n\u001b[32m      3\u001b[39m     output_struct=output_struct\n\u001b[32m      4\u001b[39m )\n\u001b[32m      6\u001b[39m abstract_concepts\n",
      "\u001b[31mNameError\u001b[39m: name 'llm_caller' is not defined"
     ]
    }
   ],
   "source": [
    "abstract_concepts = llm_caller.structed_output(\n",
    "    prompt=abstract_prompt,\n",
    "    output_struct=output_struct\n",
    ")\n",
    "\n",
    "abstract_concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c819c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(abstract_concepts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53bb1050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# label_counts = Counter([item['label'] for item in abstract_concepts])\n",
    "# print(label_counts)\n",
    "\n",
    "# expected_count = 3\n",
    "# for label in labels:\n",
    "#     assert label_counts[label] == expected_count, f\"Label {label} has wrong count!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc57549",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_io import join_path, save_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185f0463",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(obj=keyword_concepts, dir=join_path(dataset, 'concepts'), file_name='keyword_concepts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json(obj=abstract_concepts, dir=join_path(dataset, 'concepts'), file_name='abstract_concepts.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "306f80d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_line(log_path, \"concept gen done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f576ea0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
